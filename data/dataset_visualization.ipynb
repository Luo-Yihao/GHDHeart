{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# img normalization\n",
    "from torchvision import transforms\n",
    "from pytorch3d.transforms import axis_angle_to_matrix\n",
    "from pytorch3d.ops import taubin_smoothing, cubify\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from ops.medical_related import get_4chamberview_frame \n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from torch_scatter import scatter\n",
    "\n",
    "import pyvista as pv\n",
    "pv.start_xvfb(wait=0)\n",
    "pv.set_jupyter_backend('html')\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "import data.data_utils as dut\n",
    "from data.dataset import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import trimesh\n",
    "from pytorch3d.io import save_obj, load_objs_as_meshes\n",
    "from pytorch3d.transforms import axis_angle_to_matrix, matrix_to_axis_angle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:  ../../../Dataset/ACDC/database/training/\n",
      "Total number of loaded data:  200\n"
     ]
    }
   ],
   "source": [
    "dataset = MMWHSDataset_3DLabel(dataset_path='../../../Dataset/MMWHS', mode='train', modality='mixed',\n",
    "                               output_shape=(256,256,256),\n",
    "                                RML_simple = True)\n",
    "\n",
    "dataset = ACDCDataset_3DLabel(dataset_path='../../../Dataset/ACDC', mode='train', output_shape=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yihao/anaconda3/envs/MedicalImage/lib/python3.9/site-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/yihao/anaconda3/envs/MedicalImage/lib/python3.9/site-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=0)\n",
    "\n",
    "query_num = 1000\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "\n",
    "for i, example in enumerate(dataloader):\n",
    "\n",
    "    image_tem = example['image'].to(device)\n",
    "    affine_tem = example['affine'].to(device)\n",
    "    label_tem = example['label'].to(device)\n",
    "\n",
    "\n",
    "    recubified = cubify((label_tem==dataset.label_value[2]).squeeze(1).float(), 0.48)\n",
    "    \n",
    "\n",
    "    B = image_tem.shape[0]\n",
    "\n",
    "    ## -------------- Data augmentation -----------------##\n",
    "\n",
    "    coordinate_map_tem = dut.get_coord_map_3d_normalized(image_tem.shape[-3:], affine_tem)\n",
    "\n",
    "    \n",
    "\n",
    "    lv_cavity_index =  torch.where(label_tem==2)\n",
    "    lv_cavity_center = coordinate_map_tem[lv_cavity_index[0],lv_cavity_index[2],lv_cavity_index[3],lv_cavity_index[4],:]\n",
    "    lv_cavity_center = scatter(lv_cavity_center, lv_cavity_index[0], dim=0, reduce='mean')\n",
    "\n",
    "    \n",
    "\n",
    "    affine_aug_2d  = dut.random_affine(B=B, dim=2, rot_range=[-np.pi, np.pi], \n",
    "                                    scale_range=[1.,1.], trans_range=[-0.2,0.2]).to(device)\n",
    "    \n",
    "    affine_aug = torch.eye(4).to(device).unsqueeze(0).repeat(B,1,1)\n",
    "    affine_aug[...,:2,:2] = affine_aug_2d[...,:2,:2]\n",
    "    affine_aug[...,:2, 3] = affine_aug_2d[...,:2, 2]\n",
    "    \n",
    "    \n",
    "    affine_aug[...,:3, 3] = affine_aug[...,:3, 3] + lv_cavity_center \n",
    "\n",
    "    del lv_cavity_center, lv_cavity_index\n",
    "\n",
    "    Z_new, Y_new, X_new = 8, 128, 128\n",
    "\n",
    "    # Z_new = np.random.randint(32, 64)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        new_affine = affine_tem.inverse()@affine_aug\n",
    "\n",
    "        new_affine_inv = new_affine.inverse()\n",
    "\n",
    "        recubified = recubified.update_padded(recubified.verts_padded().matmul(new_affine_inv[..., :3,:3].transpose(-1,-2))+new_affine_inv[...,:3,3].unsqueeze(-2))\n",
    "\n",
    "        label_tem = dut.augment_from_affine(label_tem, new_affine, (Z_new, Y_new, X_new), mode='nearest')\n",
    "        image_tem = dut.augment_from_affine(image_tem, new_affine, (Z_new, Y_new, X_new), mode='bilinear')\n",
    "\n",
    "        example['label'] = label_tem\n",
    "        example['image'] = image_tem\n",
    "        \n",
    "        coordinate_map_tem = dut.get_coord_map_3d_normalized(image_tem.shape[-3:], torch.eye(4).to(device).unsqueeze(0).repeat(B,1,1))\n",
    "        \n",
    "        B, C, Z, Y, X = image_tem.shape\n",
    "\n",
    "\n",
    "        query_points_labeled = rearrange(coordinate_map_tem, \n",
    "                                            'b z y x c -> b (z y x) c', c=3)\n",
    "        query_points_labeled = torch.cat([query_points_labeled, \n",
    "                                        rearrange(label_tem==dataset.label_value[2], 'b 1 z y x -> b (z y x) 1')], dim=-1)\n",
    "        \n",
    "        query_points_list = []\n",
    "        target_affine_list = []\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        for b in range(B):\n",
    "            Z_rv, Y_rv, X_rv = torch.where(label_tem[b, 0]==dataset.label_value[1])\n",
    "            Z_lv, Y_lv, X_lv = torch.where(label_tem[b, 0]==dataset.label_value[2])\n",
    "            Z_cav, Y_cav, X_cav = torch.where(label_tem[b, 0]==dataset.label_value[3])\n",
    "            Z_bg, Y_bg, X_bg = torch.where(label_tem[b, 0]==dataset.label_value[0])\n",
    "            \n",
    "            Pt_rv = coordinate_map_tem[b, Z_rv, Y_rv, X_rv]\n",
    "            Pt_lv = coordinate_map_tem[b, Z_lv, Y_lv, X_lv]\n",
    "            Pt_cav = coordinate_map_tem[b, Z_cav, Y_cav, X_cav]\n",
    "\n",
    "            geom_dict = get_4chamberview_frame(Pt_cav, Pt_lv, Pt_rv)\n",
    "            target_affine_list.append(geom_dict['target_affine'])\n",
    "\n",
    "            # select the query points\n",
    "            query_points_index_0 = torch.where(((query_points_labeled[b,:,:3]).abs().max(dim=-1).values < 1.0) & (query_points_labeled[b,:,3] < 0.5))[0]\n",
    "            query_points_index_1 = torch.where(((query_points_labeled[b,:,:3]).abs().max(dim=-1).values < 1.0) & (query_points_labeled[b,:,3] > 0.5))[0]\n",
    "            query_points_index_0 = query_points_index_0[np.random.choice(query_points_index_0.shape[0], query_num//2, replace=True)]\n",
    "            query_points_index_1 = query_points_index_1[np.random.choice(query_points_index_1.shape[0], query_num//2, replace=True)]\n",
    "            query_points_index = torch.cat([query_points_index_0, query_points_index_1], dim=0)\n",
    "            query_points_list.append(query_points_labeled[b: b+1, query_points_index])\n",
    "\n",
    "        query_points_labeled = torch.cat(query_points_list, dim=0)\n",
    "        target_affine = torch.stack(target_affine_list, dim=0)\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e7533e5f0749eb9ca76b6817e39d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EmbeddableWidget(value='<iframe srcdoc=\"<!DOCTYPE html>\\n<html>\\n  <head>\\n    <meta http-equiv=&quot;Content-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bi_ventricle_trimesh = trimesh.load_mesh('../canonical_shapes/Standard_BiV.obj')\n",
    "lv_trimesh = trimesh.load_mesh('../canonical_shapes/Standard_LV_2000.obj')\n",
    "\n",
    "b = np.random.randint(0, B)\n",
    "\n",
    "lv_trimesh = lv_trimesh.apply_transform(target_affine[b].detach().cpu().numpy())\n",
    "\n",
    "recubified_trimesh = trimesh.Trimesh(vertices=recubified.verts_list()[b].detach().cpu().numpy(), \n",
    "                                     faces=recubified.faces_list()[b].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "coordinate_map_np = coordinate_map_tem[b].detach().cpu().numpy()\n",
    "\n",
    "pl = pv.Plotter(notebook=True)\n",
    "interval = 1\n",
    "if image_tem.shape[-3] > 20:\n",
    "    interval = 2\n",
    "if image_tem.shape[-3] > 256:\n",
    "    interval = 2\n",
    "for i in range(0, image_tem.shape[-3], interval):\n",
    "\n",
    "    x, y, z = coordinate_map_np[i,...,0], coordinate_map_np[i,...,1], coordinate_map_np[i,...,2]\n",
    "\n",
    "    grid = pv.StructuredGrid(x, y, z)\n",
    "\n",
    "    color_gt = (label_tem[b,0,i].cpu().numpy().T.flatten() ==2).astype(np.float32)\n",
    "    raw_image = image_tem[b,0,i].cpu().numpy().T.flatten()\n",
    "    color_opacity = np.ones_like(color_gt)*0.4\n",
    "\n",
    "    color_opacity[color_gt == 0] = 0.05\n",
    "\n",
    "    pl.add_mesh(grid, scalars = color_gt, cmap = 'Accent_r',\n",
    "                show_scalar_bar = False, opacity = color_opacity, clim=[0,3])\n",
    "    \n",
    "    \n",
    "\n",
    "pl.add_mesh(lv_trimesh, color='blue', opacity=0.1)\n",
    "\n",
    "# # pl.add_mesh(bi_ventricle_trimesh_target, color='red', opacity=0.1)\n",
    "# pl.add_mesh(lv_trimesh_target, color='blue', opacity=0.2, show_edges=True, show_vertices=True)\n",
    "# pl.add_mesh(pv.Box(bounds=[-1, 1, -1, 1, -1, 1]).outline(), color='black')\n",
    "\n",
    "# pl.add_points(Pt_center.cpu().numpy(), color='red', point_size=10)\n",
    "# pl.add_arrows(Pt_center.cpu().numpy(), 0.3*(u2d_axis).cpu().numpy(), color='blue') \n",
    "# pl.add_arrows(Pt_center.cpu().numpy(), 0.3*(l2r_axis).cpu().numpy(), color='green')\n",
    "# pl.add_arrows(Pt_center.cpu().numpy(), 0.3*(b2f_axis).cpu().numpy(), color='red')\n",
    "pl.add_mesh(pv.Box(bounds=[-1, 1, -1, 1, -1, 1]).outline(), color='black')\n",
    "\n",
    "\n",
    "pl.add_mesh(recubified_trimesh, color='red', opacity=0.1)\n",
    "\n",
    "\n",
    "# pl.add_points(lv_cavity_center.cpu().numpy(), color='red', point_size=10)\n",
    "\n",
    "pl.add_axes()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yihao/anaconda3/envs/MedicalImage/lib/python3.9/site-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/yihao/anaconda3/envs/MedicalImage/lib/python3.9/site-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=8)\n",
    "\n",
    "query_num = 1000\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "for i, example in enumerate(dataloader):\n",
    "\n",
    "    image_tem = example['image'].to(device)\n",
    "    affine_tem = example['affine'].to(device)\n",
    "    label_tem = example['label'].to(device)\n",
    "\n",
    "    B = image_tem.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "    coordinate_map_tem = dut.get_coord_map_3d_normalized(image_tem.shape[-3:], affine_tem)\n",
    "\n",
    "    lv_cavity_index =  torch.where(label_tem==2)\n",
    "    lv_cavity_center = coordinate_map_tem[lv_cavity_index[0],lv_cavity_index[2],lv_cavity_index[3],lv_cavity_index[4],:]\n",
    "    lv_cavity_center = scatter(lv_cavity_center, lv_cavity_index[0], dim=0, reduce='mean')\n",
    "\n",
    "    \n",
    "\n",
    "    affine_aug  = dut.random_affine(B=B, dim=3, rot_range=[-np.pi, np.pi], \n",
    "                                    scale_range=[1.,1.], trans_range=[-0.2,0.2]).to(device)\n",
    "    \n",
    "    affine_aug[...,:3, 3] = affine_aug[...,:3, 3] + lv_cavity_center \n",
    "\n",
    "    Z_new, Y_new, X_new = 128, 128, 128\n",
    "\n",
    "    Z_new = np.random.randint(64, 128)\n",
    "\n",
    "    new_affine = affine_tem.inverse()@affine_aug\n",
    "\n",
    "    label_tem = dut.augment_from_affine(label_tem, new_affine, (Z_new, Y_new, X_new), mode='nearest')\n",
    "    image_tem = dut.augment_from_affine(image_tem, new_affine, (Z_new, Y_new, X_new), mode='bilinear')\n",
    "    \n",
    "    coordinate_map_tem = dut.get_coord_map_3d_normalized(image_tem.shape[-3:], torch.eye(4).to(device).unsqueeze(0).repeat(B,1,1))\n",
    "    \n",
    "    B, C, Z, Y, X = image_tem.shape\n",
    "\n",
    "\n",
    "    query_points_labeled = rearrange(coordinate_map_tem, \n",
    "                                        'b z y x c -> b (z y x) c', c=3)\n",
    "    query_points_labeled = torch.cat([query_points_labeled, \n",
    "                                    rearrange(label_tem==dataset.label_value[2], 'b 1 z y x -> b (z y x) 1')], dim=-1)\n",
    "    \n",
    "    query_points_list = []\n",
    "    target_affine_list = []\n",
    "    \n",
    "\n",
    "    for b in range(B):\n",
    "        Z_rv, Y_rv, X_rv = torch.where(label_tem[b, 0]==dataset.label_value[1])\n",
    "        Z_lv, Y_lv, X_lv = torch.where(label_tem[b, 0]==dataset.label_value[2])\n",
    "        Z_cav, Y_cav, X_cav = torch.where(label_tem[b, 0]==dataset.label_value[3])\n",
    "        Z_bg, Y_bg, X_bg = torch.where(label_tem[b, 0]==dataset.label_value[0])\n",
    "        \n",
    "        Pt_rv = coordinate_map_tem[b, Z_rv, Y_rv, X_rv]\n",
    "        Pt_lv = coordinate_map_tem[b, Z_lv, Y_lv, X_lv]\n",
    "        Pt_cav = coordinate_map_tem[b, Z_cav, Y_cav, X_cav]\n",
    "\n",
    "        geom_dict = get_4chamberview_frame(Pt_cav, Pt_lv, Pt_rv)\n",
    "        target_affine_list.append(geom_dict['target_affine'])\n",
    "\n",
    "        # select the query points\n",
    "        query_points_index_0 = torch.where(((query_points_labeled[b,:,:3]).abs().max(dim=-1).values < 1.0) & (query_points_labeled[b,:,3] < 0.5))[0]\n",
    "        query_points_index_1 = torch.where(((query_points_labeled[b,:,:3]).abs().max(dim=-1).values < 1.0) & (query_points_labeled[b,:,3] > 0.5))[0]\n",
    "        query_points_index_0 = query_points_index_0[np.random.choice(query_points_index_0.shape[0], query_num//2, replace=True)]\n",
    "        query_points_index_1 = query_points_index_1[np.random.choice(query_points_index_1.shape[0], query_num//2, replace=True)]\n",
    "        query_points_index = torch.cat([query_points_index_0, query_points_index_1], dim=0)\n",
    "        query_points_list.append(query_points_labeled[b: b+1, query_points_index])\n",
    "\n",
    "    query_points_labeled = torch.cat(query_points_list, dim=0)\n",
    "    target_affine = torch.stack(target_affine_list, dim=0)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recubified = cubify((label_tem==dataset.label_value[2]).squeeze(1), 0.5)\n",
    "coordinate_map_np = coordinate_map_tem[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_ventricle_trimesh = trimesh.load_mesh('../canonical_shapes/Standard_BiV.obj')\n",
    "lv_trimesh = trimesh.load_mesh('../canonical_shapes/Standard_LV_2000.obj')\n",
    "\n",
    "lv_trimesh = lv_trimesh.apply_transform(target_affine[0].detach().cpu().numpy())\n",
    "\n",
    "recubified_trimesh = trimesh.Trimesh(vertices=recubified.verts_list()[0].detach().cpu().numpy(), faces=recubified.faces_list()[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x724d3c069220>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(label_tem[0,0,32].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 128, 128, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinate_map_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c913886996f4f88b59450b414ed2fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EmbeddableWidget(value='<iframe srcdoc=\"<!DOCTYPE html>\\n<html>\\n  <head>\\n    <meta http-equiv=&quot;Content-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl = pv.Plotter(notebook=True)\n",
    "interval = 1\n",
    "if image_tem.shape[-3] > 20:\n",
    "    interval = 5\n",
    "if image_tem.shape[-3] > 256:\n",
    "    interval = 10\n",
    "for i in range(0, image_tem.shape[-3], interval):\n",
    "\n",
    "    x, y, z = coordinate_map_np[i,...,0], coordinate_map_np[i,...,1], coordinate_map_np[i,...,2]\n",
    "\n",
    "    grid = pv.StructuredGrid(x, y, z)\n",
    "\n",
    "    color_gt = (label_tem[0,0,i].cpu().numpy().T.flatten() ==2).astype(np.float32)\n",
    "    raw_image = image_tem[0,0,i].cpu().numpy().T.flatten()\n",
    "    color_opacity = np.ones_like(color_gt)*0.4\n",
    "\n",
    "    color_opacity[color_gt == 0] = 0.05\n",
    "\n",
    "    pl.add_mesh(grid, scalars = color_gt, cmap = 'Accent_r',\n",
    "                show_scalar_bar = False, opacity = color_opacity, clim=[0,3])\n",
    "    \n",
    "    \n",
    "\n",
    "pl.add_mesh(lv_trimesh, color='blue', opacity=0.1)\n",
    "\n",
    "# # pl.add_mesh(bi_ventricle_trimesh_target, color='red', opacity=0.1)\n",
    "# pl.add_mesh(lv_trimesh_target, color='blue', opacity=0.2, show_edges=True, show_vertices=True)\n",
    "# pl.add_mesh(pv.Box(bounds=[-1, 1, -1, 1, -1, 1]).outline(), color='black')\n",
    "\n",
    "# pl.add_points(Pt_center.cpu().numpy(), color='red', point_size=10)\n",
    "# pl.add_arrows(Pt_center.cpu().numpy(), 0.3*(u2d_axis).cpu().numpy(), color='blue') \n",
    "# pl.add_arrows(Pt_center.cpu().numpy(), 0.3*(l2r_axis).cpu().numpy(), color='green')\n",
    "# pl.add_arrows(Pt_center.cpu().numpy(), 0.3*(b2f_axis).cpu().numpy(), color='red')\n",
    "pl.add_mesh(pv.Box(bounds=[-1, 1, -1, 1, -1, 1]).outline(), color='black')\n",
    "\n",
    "\n",
    "pl.add_mesh(recubified_trimesh, color='red', opacity=0.1)\n",
    "\n",
    "\n",
    "# pl.add_points(lv_cavity_center.cpu().numpy(), color='red', point_size=10)\n",
    "\n",
    "pl.add_axes()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:  ../../../Dataset/ACDC/database/training/\n",
      "Total number of loaded data:  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yihao/data/IC/IF-PINN/ops/medical_related.py:22: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3614.)\n",
      "  if u2d_axis@(Pt_center_lv-Pt_center).T < 0:\n"
     ]
    }
   ],
   "source": [
    "dataset =  ACDCDataset_Augmented(dataset_path='../../../Dataset/ACDC',mode='train', output_shape=(7, 128, 128))\n",
    "# dataset = MMWHSDataset_Augmented(dataset_path='../../../Dataset/MMWHS',mode='train',modality='mixed',\n",
    "#                                  rotation_range=[-np.pi, np.pi], scale_range=[0.9, 1.1], trans_range=[10., 10.], \n",
    "#                                  aug_dim=3,\n",
    "#                                  output_shape=(64, 128, 128), RML_simple=True)\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "dataloaders = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "query_num = 1000\n",
    "\n",
    "## Constant rescacle ##\n",
    "rescale = 1.0/100 # -1 to 1 = 200 mm\n",
    "\n",
    "indx = 0\n",
    "for i, example in enumerate(dataloaders):\n",
    "\n",
    "    image_tem = example['image'].to(device)\n",
    "    label_tem = example['label'].to(device)\n",
    "    \n",
    "    B, C, Z, Y, X = image_tem.shape\n",
    "\n",
    "    affine_tem = example['affine'].to(device)\n",
    "    affine_rand = dut.random_affine(B=B, dim=3, rot_range=[-np.pi, np.pi], \n",
    "                            trans_range=[-0.1, 0.1], scale_range=[1.0, 1.0]).to(device)\n",
    "    \n",
    "    affine_tem = torch.matmul(affine_rand, affine_tem)\n",
    "    coordinate_map_tem = dut.get_coord_map_3d(image_tem.shape[-3:], affine_tem, rescaler=rescale).to(device)\n",
    "\n",
    "\n",
    "    S = affine_tem[0,:3,:3].norm(dim=-2, keepdim=True)\n",
    "    R = affine_tem[0,:3,:3]/S\n",
    "    T = affine_tem[0,:3,3]/torch.tensor([X-1, Y-1, Z-1]).to(device).view(1,3)*2\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        ## generate the query points\n",
    "        query_points_labeled = rearrange(coordinate_map_tem, \n",
    "                                            'b z y x c -> b (z y x) c', c=3)\n",
    "        query_points_labeled = torch.cat([query_points_labeled, \n",
    "                                        rearrange(label_tem==dataset.label_value[2], 'b 1 z y x -> b (z y x) 1')], dim=-1)\n",
    "        query_pts = torch.tensor([[0, 0, 0], [0, 0, Z-1], [0, Y-1, 0], [0, Y-1, Z-1], [X-1, 0, 0], [X-1, 0, Z-1], [X-1, Y-1, 0], [X-1, Y-1, Z-1]]).to(device)\n",
    "        \n",
    "        query_points_list = []\n",
    "        target_affine_list = []\n",
    "        for b in range(B):\n",
    "            Z_rv, Y_rv, X_rv = torch.where(label_tem[b, 0]==dataset.label_value[1])\n",
    "            Z_lv, Y_lv, X_lv = torch.where(label_tem[b, 0]==dataset.label_value[2])\n",
    "            Z_cav, Y_cav, X_cav = torch.where(label_tem[b, 0]==dataset.label_value[3])\n",
    "            Z_bg, Y_bg, X_bg = torch.where(label_tem[b, 0]==dataset.label_value[0])\n",
    "            \n",
    "\n",
    "            Pt_rv = coordinate_map_tem[b, Z_rv, Y_rv, X_rv]\n",
    "            Pt_lv = coordinate_map_tem[b, Z_lv, Y_lv, X_lv]\n",
    "            Pt_cav = coordinate_map_tem[b, Z_cav, Y_cav, X_cav]\n",
    "\n",
    "            geom_dict = get_4chamberview_frame(Pt_cav, Pt_lv, Pt_rv)\n",
    "            target_affine_list.append(geom_dict['target_affine'])\n",
    "\n",
    "            # select the query points\n",
    "            query_points_index_0 = torch.where(((query_points_labeled[b,:,:3]).abs().max(dim=-1).values < 1.0) & (query_points_labeled[b,:,3] < 0.5))[0]\n",
    "            query_points_index_1 = torch.where(((query_points_labeled[b,:,:3]).abs().max(dim=-1).values < 1.0) & (query_points_labeled[b,:,3] > 0.5))[0]\n",
    "            query_points_index_0 = query_points_index_0[np.random.choice(query_points_index_0.shape[0], query_num//2, replace=True)]\n",
    "            query_points_index_1 = query_points_index_1[np.random.choice(query_points_index_1.shape[0], query_num//2, replace=True)]\n",
    "            query_points_index = torch.cat([query_points_index_0, query_points_index_1], dim=0)\n",
    "            query_points_list.append(query_points_labeled[b: b+1, query_points_index])\n",
    "\n",
    "        query_points_labeled = torch.cat(query_points_list, dim=0)\n",
    "        target_affine = torch.stack(target_affine_list, dim=0)\n",
    "\n",
    "\n",
    "    if i==indx:\n",
    "        break\n",
    "    \n",
    "\n",
    "coordinate_map_np = rearrange(coordinate_map_tem, '1 z y x d-> z y x d').detach().cpu().numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_frame = torch.tensor([[-1, 0, 0], [0, 1, 0], [0, 0, -1]]).T.float().to(device)\n",
    "for b in range(B):\n",
    "    with torch.no_grad():\n",
    "        Z_rv, Y_rv, X_rv = torch.where(label_tem[b, 0]==dataset.label_value[1])\n",
    "        Z_lv, Y_lv, X_lv = torch.where(label_tem[b, 0]==dataset.label_value[2])\n",
    "        Z_cav, Y_cav, X_cav = torch.where(label_tem[b, 0]==dataset.label_value[3])\n",
    "        Z_bg, Y_bg, X_bg = torch.where(label_tem[b, 0]==dataset.label_value[0])\n",
    "        \n",
    "\n",
    "        Pt_rv = coordinate_map_tem[b, Z_rv, Y_rv, X_rv]\n",
    "        Pt_lv = coordinate_map_tem[b, Z_lv, Y_lv, X_lv]\n",
    "        Pt_cav = coordinate_map_tem[b, Z_cav, Y_cav, X_cav]\n",
    "\n",
    "        geom_dict = get_4chamberview_frame(Pt_cav, Pt_lv, Pt_rv)\n",
    "        \n",
    "\n",
    "\n",
    " \n",
    "        # R = torch.matmul(target_frame,canonical_frame.T)\n",
    "        # T = Pt_center\n",
    "\n",
    "        # target_affine = torch.eye(4).to(device)\n",
    "        # target_affine[:3,:3] = R\n",
    "        # target_affine[:3,3] = T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_ventricle_trimesh = trimesh.load_mesh('../canonical_shapes/Standard_BiV.obj')\n",
    "lv_trimesh = trimesh.load_mesh('../canonical_shapes/Standard_LV_2000.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_affine = geom_dict['target_affine']\n",
    "Pt_center = geom_dict['mean_cav']\n",
    "Pt_center_lv = geom_dict['mean_lv']\n",
    "Pt_center_rv = geom_dict['mean_rv']\n",
    "b2f_axis = geom_dict['b2f_axis']\n",
    "l2r_axis = geom_dict['l2r_axis']\n",
    "u2d_axis = geom_dict['u2d_axis']\n",
    "bi_ventricle_trimesh_target = bi_ventricle_trimesh.copy().apply_transform(target_affine.cpu().numpy())\n",
    "lv_trimesh_target = lv_trimesh.copy().apply_transform(target_affine.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9481,  0.2497, -0.1969, -0.0389],\n",
       "        [ 0.0858, -0.3952, -0.9146, -0.0695],\n",
       "        [-0.3062, -0.8840,  0.3533,  0.0361],\n",
       "        [ 0.0000,  0.0000,  0.0000,  1.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc557c97a19a479db13ec78751a500bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EmbeddableWidget(value='<iframe srcdoc=\"<!DOCTYPE html>\\n<html>\\n  <head>\\n    <meta http-equiv=&quot;Content-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl = pv.Plotter(notebook=True)\n",
    "interval = 1\n",
    "if image_tem.shape[-3] > 20:\n",
    "    interval = 3\n",
    "if image_tem.shape[-3] > 256:\n",
    "    interval = 10\n",
    "for i in range(0, image_tem.shape[-3], interval):\n",
    "\n",
    "    x, y, z = coordinate_map_np[i,...,0], coordinate_map_np[i,...,1], coordinate_map_np[i,...,2]\n",
    "\n",
    "    grid = pv.StructuredGrid(x, y, z)\n",
    "\n",
    "    color_gt = label_tem[0,0,i].cpu().numpy().T.flatten()\n",
    "    raw_image = image_tem[0,0,i].cpu().numpy().T.flatten()\n",
    "    color_opacity = np.ones_like(color_gt)*0.2\n",
    "\n",
    "    color_opacity[color_gt == 0] = 0.1\n",
    "\n",
    "    pl.add_mesh(grid, scalars = color_gt, cmap = 'Accent_r',\n",
    "                show_scalar_bar = False, opacity = color_opacity, clim=[0, 3])\n",
    "    \n",
    "    \n",
    "\n",
    "# trimesh_lv = trimesh.Trimesh(vertices=mesh_lv.verts_list()[0].detach().cpu().numpy()/100, faces=mesh_lv.faces_list()[0].detach().cpu().numpy())\n",
    "# simplified_mesh = trimesh_lv.simplify_quadratic_decimation(4000)\n",
    "# trimesh.smoothing.filter_taubin(simplified_mesh, iterations=10)\n",
    "# decimate the mesh\n",
    "# pl.add_mesh(simplified_mesh, color='blue', opacity=0.1)\n",
    "\n",
    "# pl.add_mesh(bi_ventricle_trimesh_target, color='red', opacity=0.1)\n",
    "pl.add_mesh(lv_trimesh_target, color='blue', opacity=0.2, show_edges=True, show_vertices=True)\n",
    "pl.add_mesh(pv.Box(bounds=[-1, 1, -1, 1, -1, 1]).outline(), color='black')\n",
    "\n",
    "pl.add_points(Pt_center.cpu().numpy(), color='red', point_size=10)\n",
    "pl.add_arrows(Pt_center.cpu().numpy(), 0.3*(u2d_axis).cpu().numpy(), color='blue') \n",
    "pl.add_arrows(Pt_center.cpu().numpy(), 0.3*(l2r_axis).cpu().numpy(), color='green')\n",
    "pl.add_arrows(Pt_center.cpu().numpy(), 0.3*(b2f_axis).cpu().numpy(), color='red')\n",
    "\n",
    "pl.add_axes()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MedicalImage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
